{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a02d2d6",
   "metadata": {},
   "source": [
    "# **Pandas Tips and Tricks Lec 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbce22c",
   "metadata": {},
   "source": [
    "## 11 - Copy data from clipboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ef797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "df.to_excel('khasti.xlsx') # save the titanic dataset in khasti.xlsx file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97fa484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I copy the some of data from the khasti excel file by ctrl + c and this data is store on clipboard\n",
    "# read the data from clipboard in python \n",
    "df = pd.read_clipboard()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b699370",
   "metadata": {},
   "source": [
    "## 12 - Split the dataframe into 2 subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb28103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "df.shape # give the rows and columns\n",
    "len(df) # gives the total number of rows in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ffdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "# split the dataframe into 2 subsets \n",
    "khasti_1 = df.sample(frac=0.5, random_state=1)\n",
    "khasti_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd74a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "khasti_2 = df.drop(khasti_1.index) # exclude the index of the khasti_1 \n",
    "khasti_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df)) # no of total rows in main dataframe \n",
    "print(len(khasti_1) + len(khasti_2)) # no of rows of total rows of khasti_1 and khasti_2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e3b5e",
   "metadata": {},
   "source": [
    "## 13 - Join 2 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7593b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join 2 dataframes into single dataframes using concat instead of append bcz append is not working now\n",
    "df_1 = pd.concat([khasti_1, khasti_2])\n",
    "df_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6eee81",
   "metadata": {},
   "source": [
    "## 14 - Filtering the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9ac19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # using the titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cd232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the how many values of genders in the sex column\n",
    "df.sex.unique() # 2 values in sex column like male and female "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20920667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the female data from the datasets\n",
    "df[(df.sex == 'female')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a804568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data by using mutiple values of different column using with the help of logical operater\n",
    "df[(df.sex == 'female') & (df.embark_town == 'Cherbourg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way of filtering in the dataset\n",
    "df[df.embark_town.isin(['Cherbourg', 'Queenstown'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering using comparison operaters\n",
    "df[df.age > 30].head() \n",
    "df[df.age < 30].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d08c6",
   "metadata": {},
   "source": [
    "## 15 -  Filtering by large categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13913532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by large categories\n",
    "print(df.embark_town.value_counts())\n",
    "print(df.who.value_counts())\n",
    "print(df.age.value_counts())\n",
    "print(df.alive.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96395fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.age.value_counts()\n",
    "print(counts)\n",
    "print(counts.nlargest(5)) # first largest value u want \n",
    "print(counts.nlargest(5).index) # index of largest value if u want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3919d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age.isin(counts.nlargest(1).index)].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
