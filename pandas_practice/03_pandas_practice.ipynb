{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a95cd92",
   "metadata": {},
   "source": [
    "# **Pandas Day 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0cde88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary Libraries for EDA \n",
    "\n",
    "import pandas as pd  \n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169ef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data set from seaborn and store in object \n",
    "\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cddf061",
   "metadata": {},
   "source": [
    "## **Basic Information :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db806254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata about dataset\n",
    "\n",
    "# df.info # This gives a reference to the info() method of the DataFrame, but does not execute it.\n",
    "df.info() # run actual function when use brackets\n",
    "\n",
    "# summary of Dataset\n",
    "df.describe()\n",
    "\n",
    "# find the columns name \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4803d8",
   "metadata": {},
   "source": [
    "### 🔍 Difference Between `object` and `category` in Pandas :\n",
    "\n",
    "#### ✅ **`object` dtype :**\n",
    "- General-purpose type for text or mixed data.\n",
    "- Commonly used for **strings**.\n",
    "- **Slower** and **uses more memory**.\n",
    "- Not optimized for repeated values.\n",
    "\n",
    "#### ✅ **`category` dtype :**\n",
    "- Used for **categorical data** with fixed and repeated values.\n",
    "- Internally stored as **integers with labels (lookup table)**.\n",
    "- **Faster**, more efficient, and uses **less memory**.\n",
    "- Great for grouping, filtering, and saving memory.\n",
    "\n",
    "### 📊 Comparison Table :\n",
    "\n",
    "| Feature           | `object`                      | `category`                          |\n",
    "|------------------|-------------------------------|-------------------------------------|\n",
    "| Type             | General-purpose               | Optimized for categorical data      |\n",
    "| Memory Usage     | High                          | Low                                 |\n",
    "| Speed            | Slower                        | Faster for filtering/grouping       |\n",
    "| Ideal Use        | Free-form text, mixed values  | Repeating fixed categories          |\n",
    "| Encoding         | Plain text                    | Encoded as integers with labels     |\n",
    "\n",
    "### 💡 Example :\n",
    "\n",
    "```python\n",
    "# Object type (default for strings)\n",
    "df['gender'] = ['Male', 'Female', 'Male']\n",
    "print(df['gender'].dtype)  # Output: object\n",
    "\n",
    "# Convert to category type\n",
    "df['gender'] = df['gender'].astype('category')\n",
    "print(df['gender'].dtype)  # Output: category\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the missing values / null values / NaNs in the columns\n",
    "df.isnull() # False = Value hai & True = Value missing hai\n",
    "df.isnull().sum() # In which column how many values are missing \n",
    "df.isnull().sum() / len(df) * 100 # calculate the percentage of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51708ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to find or chk the missing values in the columns by using heatgraph\n",
    "sns.heatmap(df.isnull()) # with color bar \n",
    "sns.heatmap(df.isnull(), cbar=False) # without color bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada519a",
   "metadata": {},
   "source": [
    "# 📘 Assignment No. 1: What is Mean, Median, and Mode?\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 1. Mean (Average)\n",
    "\n",
    "**Definition:**  \n",
    "Mean is the **average** of a list of numbers.  \n",
    "It is calculated by adding all the values and dividing by the number of values.\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "Mean = (Sum of all values) / (Total number of values)\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Values = [4, 7, 10, 5, 6]\n",
    "Mean = (4 + 7 + 10 + 5 + 6) / 5 = 32 / 5 = 6.4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 2. Median\n",
    "\n",
    "**Definition:**  \n",
    "Median is the **middle value** in a sorted list of numbers.  \n",
    "It separates the data into two equal halves.\n",
    "\n",
    "- If the number of values is **odd**, median is the middle value.\n",
    "- If **even**, median is the average of the two middle values.\n",
    "\n",
    "**Example 1 (Odd number of values):**\n",
    "```\n",
    "Values = [3, 5, 7]\n",
    "Median = 5 (middle value)\n",
    "```\n",
    "\n",
    "**Example 2 (Even number of values):**\n",
    "```\n",
    "Values = [2, 4, 6, 8]\n",
    "Median = (4 + 6) / 2 = 5.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 3. Mode\n",
    "\n",
    "**Definition:**  \n",
    "Mode is the value that appears **most frequently** in a dataset.\n",
    "\n",
    "- A dataset can have **one mode**, **more than one mode**, or **no mode**.\n",
    "\n",
    "**Example 1:**\n",
    "```\n",
    "Values = [3, 5, 7, 5, 9]\n",
    "Mode = 5 (occurs twice)\n",
    "```\n",
    "\n",
    "**Example 2 (No mode):**\n",
    "```\n",
    "Values = [1, 2, 3, 4]\n",
    "Mode = None (all values appear once)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Summary Table\n",
    "\n",
    "| Term   | Meaning                         | Use Case                           |\n",
    "|--------|----------------------------------|-------------------------------------|\n",
    "| Mean   | Average of all values            | For normally distributed data       |\n",
    "| Median | Middle value in sorted data      | For skewed data or with outliers    |\n",
    "| Mode   | Most frequent value              | For categorical or repeating data   |\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Extra: Python Example\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from statistics import mode\n",
    "\n",
    "data = [4, 7, 10, 5, 6]\n",
    "\n",
    "mean = np.mean(data)\n",
    "median = np.median(data)\n",
    "mode_value = mode(data)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Mode:\", mode_value)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a87989",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 📘 Assignment No. 2: How to Impute Missing Values?\n",
    "\n",
    "---\n",
    "\n",
    "## ❓ What are Missing Values?\n",
    "\n",
    "Missing values are the empty or null entries in a dataset.  \n",
    "In Pandas, they are usually represented as `NaN` (Not a Number).\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 What is Imputation?\n",
    "\n",
    "**Imputation** means filling in missing values using some technique, so that the dataset becomes complete and can be used for analysis or modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Methods to Impute Missing Values\n",
    "\n",
    "### ✅ 1. **Removing Missing Values**\n",
    "- Use when missing data is small and random.\n",
    "- You can remove rows or columns with missing data.\n",
    "\n",
    "```python\n",
    "df.dropna()         # Removes rows with any missing value\n",
    "df.dropna(axis=1)   # Removes columns with missing values\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 2. **Mean Imputation**\n",
    "- Replace missing values with the **mean** (average) of the column.\n",
    "- Best for **numeric data** with no extreme outliers.\n",
    "\n",
    "```python\n",
    "df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3. **Median Imputation**\n",
    "- Use the **median** value to fill missing data.\n",
    "- Good when data has **outliers or is skewed**.\n",
    "\n",
    "```python\n",
    "df['salary'].fillna(df['salary'].median(), inplace=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 4. **Mode Imputation**\n",
    "- Use the **most frequent value** (mode).\n",
    "- Common for **categorical data** (e.g., gender, city, etc.)\n",
    "\n",
    "```python\n",
    "df['gender'].fillna(df['gender'].mode()[0], inplace=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 5. **Constant/Fixed Value Imputation**\n",
    "- Fill missing values with a specific value like `\"Unknown\"` or `0`.\n",
    "\n",
    "```python\n",
    "df['city'].fillna('Unknown', inplace=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 6. **Forward Fill (ffill)**\n",
    "- Fill missing value with the **previous value** in the column.\n",
    "\n",
    "```python\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 7. **Backward Fill (bfill)**\n",
    "- Fill missing value with the **next value** in the column.\n",
    "\n",
    "```python\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 8. **Advanced Techniques (Optional for ML)**\n",
    "- **KNN Imputation**\n",
    "- **Regression Imputation**\n",
    "- **Multivariate Imputation by Chained Equations (MICE)**\n",
    "> These are used in machine learning when more accuracy is needed.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Summary Table\n",
    "\n",
    "| Method               | Description                                | Best For                |\n",
    "|----------------------|--------------------------------------------|--------------------------|\n",
    "| Drop Missing          | Remove rows or columns with NaN            | When few values are missing |\n",
    "| Mean Imputation       | Fill with average                          | Numeric, no outliers     |\n",
    "| Median Imputation     | Fill with median                           | Numeric, skewed data     |\n",
    "| Mode Imputation       | Fill with most common value                | Categorical data         |\n",
    "| Constant Value        | Fill with fixed value                      | Custom cases             |\n",
    "| Forward Fill (ffill)  | Use previous value                         | Time series              |\n",
    "| Backward Fill (bfill) | Use next value                             | Time series              |\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Python Example\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'age': [25, np.nan, 30, 22, np.nan],\n",
    "    'gender': ['Male', 'Female', np.nan, 'Female', 'Male']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fill missing age with mean\n",
    "df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "\n",
    "# Fill missing gender with mode\n",
    "df['gender'].fillna(df['gender'].mode()[0], inplace=True)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 Conclusion\n",
    "\n",
    "- Imputation helps make datasets usable and prevents errors in analysis or machine learning.\n",
    "- Choose the method based on **data type**, **distribution**, and **use case**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First tecnique to remove missing values\n",
    "\n",
    "print(df.shape)\n",
    "# missing values rows and columns remove form the dataset\n",
    "df.dropna().shape # remove missing values rows\n",
    "df.dropna(axis=1).shape # removes missing values column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second technique to handle missing value by using mean imputation \n",
    "\n",
    "df['age'] = df['age'].fillna(df['age'].mean()) # assign the final reuslt to age column \n",
    "# or Use fillna on the whole DataFrame\n",
    "df.fillna({'age' : df['age'].mean()}, inplace=True) # fillna apply on the whole dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ebcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third technique to handle missing values by using median imputation\n",
    "\n",
    "df['age'] = df['age'].fillna(df['age'].median()) # assign the final reuslt to age column\n",
    "# or Use fillna on the whole DataFrame\n",
    "df.fillna({'age' : df['age'].median()}, inplace=True) # fillna apply on the whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "841e1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forth technique to handle missing values by using mode imputation\n",
    "\n",
    "df['sex'] = df['sex'].fillna(df['sex'].mode()[0]) # assign the final reuslt to sex column\n",
    "# or Use fillna on the whole DataFrame\n",
    "df.fillna({'sex' : df['sex'].mode()[0]}, inplace=True) # fillna apply on the whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a557849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifth technique to handle missing values by using constant value / fixed imputation\n",
    "\n",
    "df['embarked'] = df['embarked'].fillna('unknown') # assign the final reuslt to sex column\n",
    "# or Use fillna on the whole DataFrame\n",
    "df.fillna({'embarked' : 'unknown'}, inplace=True) # fillna apply on the whole dataframe\n",
    "# or apply fillna() function more than one columnn\n",
    "df.fillna({'embarked': 'unknown', 'age': df['age'].median()}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d25489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sixth technique to handle missing values by using forward fill imputation\n",
    "\n",
    "df['age'] = df['age'].ffill() # forward fill only 'age'\n",
    "# or apply on whole dataframe\n",
    "df.ffill(inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0206fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seventh technique to handle missing values by using backward fill imputation\n",
    "\n",
    "df['age'] = df['age'].bfill() # forward fill only 'age'\n",
    "# or apply on whole dataframe\n",
    "df.bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f20752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select specific columns form the dataset\n",
    "df.sex # select one column ( ye wala tariqa professional nhi hai )\n",
    "df['sex'] # select one column ( ye wala tariqa professional hai )\n",
    "df[['sex', 'age']] # select 2 columns form the dataset\n",
    "df[['sex', 'age', 'embarked']] # select more than 2 column from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique function used with the series only ( mean used with one dimension )\n",
    "\n",
    "# find the unique values in the columns \n",
    "df.sex.unique() # find the unique values in the column ( not professional )\n",
    "df['sex'].unique() # find the unique values in the column ( professional )\n",
    "df['sex'].nunique() # find the number of unique values in the columns\n",
    "\n",
    "df.nunique() # find the number of uniques values of all the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead96755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in columns, how many time the values repeat it seld count by value count\n",
    "df['embark_town'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e23ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic summary \n",
    "df.describe()\n",
    "\n",
    "# find the mean of fare of both male and female using groupby \n",
    "df.groupby('sex')['fare'].mean()\n",
    "\n",
    "# find the mean of fare based on class type of both male and female using groupby\n",
    "df.groupby(['sex','pclass'])['fare'].mean()\n",
    "\n",
    "# find the values count by using groupby \n",
    "df.groupby(['sex', 'embarked']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b325515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make correlation matric\n",
    "correlaton_df = df[['fare', 'age', 'parch', 'sibsp']].corr()\n",
    "correlaton_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21be0d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the heatmap of correlation dataframe \n",
    "sns.heatmap(correlaton_df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14799163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pairplot of dataset\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b3096",
   "metadata": {},
   "source": [
    "## 📊 What is EDA (Exploratory Data Analysis)?\n",
    "\n",
    "**EDA (Exploratory Data Analysis)** is the process of examining your dataset before applying any machine learning or statistical modeling. The goal is to understand:\n",
    "- What the data contains\n",
    "- Its structure\n",
    "- Patterns, trends, and anomalies\n",
    "- Whether the data is clean or needs preprocessing\n",
    "\n",
    "## 🔍 Questions to Ask in EDA\n",
    "\n",
    "### 1. **Who Collected the Data?**\n",
    "- Understand the **source** of data.\n",
    "- Was it collected by a **reliable organization**, a **survey**, **sensor**, **government**, or **scraped from a website**?\n",
    "\n",
    "### 2. **What is the Data About?**\n",
    "- What is the **context** of the data?\n",
    "- What is the **main topic** — e.g., health records, sales data, weather, population, etc.?\n",
    "- What is the **goal** of analyzing it?\n",
    "\n",
    "---\n",
    "\n",
    "## 🗂️ What is Metadata?\n",
    "\n",
    "**Metadata = Data about Data**\n",
    "\n",
    "It gives information **about** the dataset, such as:\n",
    "- Column names\n",
    "- Data types (int, float, string, etc.)\n",
    "- Units (e.g., cm, $, °C)\n",
    "- Description of fields\n",
    "- When and how it was collected\n",
    "\n",
    "> For example:  \n",
    "> In a CSV file of student records, metadata tells us that  \n",
    "> `age` is a number, `name` is a string, and `grade` is a float.\n",
    "\n",
    "---\n",
    "\n",
    "## 📐 Data Dimensions\n",
    "\n",
    "Data dimensions refer to the **shape** of the dataset:\n",
    "\n",
    "- **Rows = Observations** (Each record or sample)\n",
    "- **Columns = Features/Variables** (Each attribute of the observation)\n",
    "\n",
    "You can find the dimensions using:\n",
    "```python\n",
    "df.shape  # (rows, columns)\n",
    "```\n",
    "\n",
    "### Example:\n",
    "If `df.shape` returns `(100, 5)`:\n",
    "- There are **100 records (rows)**.\n",
    "- Each record has **5 attributes (columns)**.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Summary Table\n",
    "\n",
    "| Term             | Meaning                                                       |\n",
    "|------------------|---------------------------------------------------------------|\n",
    "| EDA              | Explore and understand dataset                                |\n",
    "| Data Source      | Who collected or provided the data                            |\n",
    "| Data Meaning     | What the dataset represents                                   |\n",
    "| Metadata         | Info about the data (e.g., types, descriptions, units)        |\n",
    "| Data Dimensions  | Shape of data (rows = samples, columns = features)            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8fd850",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📊 Understanding Key EDA Concepts\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 1. **Data**\n",
    "- Data is a **collection of raw facts and figures**.\n",
    "- In EDA, data is usually organized in rows (records) and columns (features).\n",
    "- Example:\n",
    "  ```plaintext\n",
    "  Name     Age   Gender   Salary\n",
    "  Alice    28    Female   50000\n",
    "  Bob      35    Male     62000\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 2. **Compositions**\n",
    "- Shows **what the data is made of** — the **proportions or categories** within a feature.\n",
    "- Useful for analyzing **categorical columns** like gender, region, product type.\n",
    "- Example tools:\n",
    "  - Bar chart\n",
    "  - Pie chart\n",
    "  - Value counts\n",
    "\n",
    "```python\n",
    "df['gender'].value_counts()\n",
    "df['region'].value_counts(normalize=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 3. **Correlations**\n",
    "- Measure of how **two numerical variables are related**.\n",
    "- Value ranges from **-1 to 1**:\n",
    "  - `+1`: strong positive relationship\n",
    "  - `0`: no relationship\n",
    "  - `-1`: strong negative relationship\n",
    "- Useful for understanding **dependencies** or **multicollinearity**.\n",
    "\n",
    "```python\n",
    "df.corr()\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 4. **Comparisons**\n",
    "- Comparing **two or more groups** based on a feature.\n",
    "- Example: Average income of males vs females.\n",
    "- Useful for finding differences or trends between categories.\n",
    "\n",
    "```python\n",
    "df.groupby('gender')['income'].mean()\n",
    "sns.boxplot(x='gender', y='income', data=df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 5. **Distributions**\n",
    "- Shows how data values are **spread out**.\n",
    "- Helps identify:\n",
    "  - Skewness\n",
    "  - Outliers\n",
    "  - Central tendency\n",
    "- Tools:\n",
    "  - Histogram\n",
    "  - KDE plot\n",
    "  - Boxplot\n",
    "\n",
    "```python\n",
    "sns.histplot(df['age'], kde=True)\n",
    "sns.boxplot(y=df['salary'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Summary Table\n",
    "\n",
    "| Concept       | Purpose                                       | Visual Tools                      |\n",
    "|---------------|-----------------------------------------------|-----------------------------------|\n",
    "| Data          | Raw information (rows × columns)              | `.head()`, `.info()`, `.shape`    |\n",
    "| Composition   | Breakdown of categories/proportions           | Bar chart, Pie chart              |\n",
    "| Correlation   | Relationship between numerical variables       | Correlation matrix, Heatmap       |\n",
    "| Comparison    | Difference between groups/categories           | Boxplot, GroupBy + Mean           |\n",
    "| Distribution  | Spread of values in a column                   | Histogram, KDE plot, Boxplot      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa0e7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📈 Pearson vs Spearman Correlation\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 1. **Pearson Correlation**\n",
    "- Measures **linear relationship** between two **continuous numeric variables**.\n",
    "- Assumes:\n",
    "  - Data is **normally distributed**\n",
    "  - Relationship is **linear**\n",
    "- Value range: `-1` to `+1`\n",
    "  - `+1`: Perfect positive linear relationship\n",
    "  - `0`: No linear correlation\n",
    "  - `-1`: Perfect negative linear relationship\n",
    "\n",
    "#### ✅ Use When:\n",
    "- Data is **continuous**\n",
    "- Relationship is **linear**\n",
    "- No major outliers\n",
    "\n",
    "```python\n",
    "df.corr(method='pearson')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 2. **Spearman Correlation**\n",
    "- Measures **monotonic relationship** using **ranked data**.\n",
    "- Does **not require linearity** or normal distribution.\n",
    "- Value range: `-1` to `+1` (based on rank correlation)\n",
    "\n",
    "#### ✅ Use When:\n",
    "- Data is **ordinal**\n",
    "- Relationship is **non-linear but monotonic**\n",
    "- There are **outliers**\n",
    "\n",
    "```python\n",
    "df.corr(method='spearman')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Comparison Table\n",
    "\n",
    "| Feature              | Pearson                         | Spearman                        |\n",
    "|----------------------|----------------------------------|----------------------------------|\n",
    "| Measures             | Linear relationship              | Monotonic relationship (ranks)  |\n",
    "| Data type            | Continuous numeric               | Ordinal, ranked, or numeric     |\n",
    "| Sensitive to outliers| Yes                              | No                               |\n",
    "| Requires normality   | Yes                              | No                               |\n",
    "| Method used          | Raw values                       | Ranked values                   |\n",
    "| Use case             | Linear data                      | Non-linear or ranked data       |\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 Example in Code\n",
    "\n",
    "```python\n",
    "# Pearson correlation\n",
    "df.corr(method='pearson')\n",
    "\n",
    "# Spearman correlation\n",
    "df.corr(method='spearman')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary:\n",
    "- Use **Pearson** for **linear, clean numeric** data.\n",
    "- Use **Spearman** when data is **ordinal**, **non-linear**, or has **outliers**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e9f3e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📊 Key Steps in Data Handling\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 1. **Data Exploration**\n",
    "- First step of understanding the dataset.\n",
    "- Involves checking:\n",
    "  - Structure of data (rows, columns)\n",
    "  - Data types\n",
    "  - Summary statistics\n",
    "  - Missing values, duplicates, or anomalies\n",
    "- Tools: `df.info()`, `df.describe()`, `.head()`, `.value_counts()`\n",
    "\n",
    "```python\n",
    "df.info()\n",
    "df.describe()\n",
    "df['gender'].value_counts()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 2. **Data Wrangling**\n",
    "- Also called **data transformation** or **reshaping**.\n",
    "- Process of **converting raw data into a usable format**.\n",
    "- Includes:\n",
    "  - Merging datasets\n",
    "  - Splitting columns\n",
    "  - Restructuring (pivoting/unpivoting)\n",
    "  - Handling nested or messy data\n",
    "\n",
    "```python\n",
    "df = df.pivot_table(index='city', columns='year', values='population')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 3. **Data Munging**\n",
    "- Similar to **data wrangling** — often used interchangeably.\n",
    "- Focuses on **converting complex or unstructured data into clean format**.\n",
    "- Useful when data comes from web scraping, logs, APIs, or inconsistent sources.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧼 4. **Data Cleaning**\n",
    "- Removing or fixing **errors**, **incomplete**, **duplicate**, or **inconsistent** data.\n",
    "- Steps may include:\n",
    "  - Handling missing values\n",
    "  - Removing duplicates\n",
    "  - Correcting typos or formatting issues\n",
    "\n",
    "```python\n",
    "df.dropna()             # remove missing values\n",
    "df.duplicated().sum()   # check duplicates\n",
    "df['salary'] = df['salary'].str.replace('$', '').astype(float)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ 5. **Data Preprocessing**\n",
    "- Preparing data for **machine learning or statistical modeling**.\n",
    "- Combines:\n",
    "  - Cleaning\n",
    "  - Encoding categorical variables\n",
    "  - Scaling/normalizing data\n",
    "  - Feature engineering\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[['age', 'income']] = scaler.fit_transform(df[['age', 'income']])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Summary Table\n",
    "\n",
    "| Step              | Purpose                                                    |\n",
    "|-------------------|------------------------------------------------------------|\n",
    "| Data Exploration  | Understand the structure, types, and overview of the data  |\n",
    "| Data Wrangling    | Reshape and reformat raw data for analysis                 |\n",
    "| Data Munging      | Clean and convert messy/unstructured data                  |\n",
    "| Data Cleaning     | Fix errors, missing values, duplicates, typos              |\n",
    "| Data Preprocessing| Prepare clean data for ML models (scaling, encoding, etc.) |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
